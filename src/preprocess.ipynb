{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../'\n",
    "\n",
    "import os, sys\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import mask_rcnn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic settings\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "cfg = []\n",
    "\n",
    "torch.manual_seed(470)\n",
    "torch.cuda.manual_seed(470)\n",
    "\n",
    "args = edict()\n",
    "args.batch_size = 1\n",
    "args.lr = 1e-4\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 5e-4\n",
    "args.epoch = 10\n",
    "args.tensorboard = False\n",
    "args.gpu = True\n",
    "args.train_portion = 0.7\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
    "\n",
    "# Create directory name.\n",
    "result_dir = Path(root) / 'results'\n",
    "result_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.tensorboard:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir \"{str(result_dir)}\" --samples_per_plugin images=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbs(shape, bbs):\n",
    "    if (torch.is_tensor(bbs)):\n",
    "        bbs = np.array(bbs.tolist())\n",
    "    if (torch.is_tensor(shape)):\n",
    "        [h, w] = np.array(shape.tolist())\n",
    "        shape = (h, w)\n",
    "    \n",
    "    h, w = shape\n",
    "    fig, ax = plt.subplots(1)\n",
    "    background=patches.Rectangle((0, 0), w, h, linewidth=2, edgecolor='b', facecolor='black')\n",
    "    ax.add_patch(background)\n",
    "    for bb in bbs:\n",
    "        rect = patches.Rectangle((bb[0], bb[1]), bb[2], bb[3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    ax.autoscale(True, 'both')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def get_BB_types(bbs):\n",
    "    return bbs[:, 4]\n",
    "\n",
    "class BBSlideDeckDataset(Dataset):\n",
    "    \"\"\" Slide Deck Dataset but with Bounding Boxes\"\"\"\n",
    "    def __init__(self, slide_deck_data, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.slide_deck_data = slide_deck_data\n",
    "        self.slide_deck_ids = list(self.slide_deck_data.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.slide_deck_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        slide_deck_id = self.slide_deck_ids[idx]\n",
    "        (h, w) = self.slide_deck_data[slide_deck_id][\"shape\"]\n",
    "        lengths_slide_deck = []\n",
    "        slides = []\n",
    "        max_len_bbs = 0\n",
    "        for slide in self.slide_deck_data[slide_deck_id][\"slides\"]:\n",
    "            lengths_slide_deck.append(len(slide))\n",
    "            if len(slide) > max_len_bbs:\n",
    "                max_len_bbs = len(slide)\n",
    "        for slide in self.slide_deck_data[slide_deck_id][\"slides\"]:\n",
    "            np_slide = np.zeros((max_len_bbs, 5))\n",
    "            for i, bb in enumerate(slide):\n",
    "                np_slide[i] = bb\n",
    "            slides.append(np_slide)\n",
    "\n",
    "        ref_slide = slides[0]\n",
    "        slide_deck = slides[1:]\n",
    "        length_ref_types = lengths_slide_deck.pop(0)\n",
    "        sample = {\n",
    "            \"shape\": (h, w),\n",
    "            \"ref_slide\": ref_slide,\n",
    "            \"ref_types\": get_BB_types(ref_slide),\n",
    "            \"slide_deck\": np.asarray(slide_deck),\n",
    "            \"lengths_slide_deck\": lengths_slide_deck,\n",
    "            \"length_ref_types\": length_ref_types,\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescaleBB(object):\n",
    "    \"\"\"Rescale the bounding boxes in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def _resize_single_slide(self, slide, original_shape, new_shape):\n",
    "        h, w = original_shape\n",
    "        new_h, new_w = new_shape\n",
    "        slide = slide * np.array([new_w / w, new_h / h, new_w / w, new_h / h, 1]).T\n",
    "        return slide\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        h, w = sample[\"shape\"]\n",
    "        ref_slide = sample[\"ref_slide\"]\n",
    "        ref_types = sample[\"ref_types\"]\n",
    "        slide_deck = sample[\"slide_deck\"]\n",
    "        lengths_slide_deck = sample[\"lengths_slide_deck\"]\n",
    "        length_ref_types = sample[\"length_ref_types\"]\n",
    "\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        ref_slide = self._resize_single_slide(ref_slide, (h, w), (new_h, new_w))\n",
    "        for i, slide in enumerate(slide_deck):\n",
    "            slide_deck[i] = self._resize_single_slide(slide, (h, w), (new_h, new_w))\n",
    "\n",
    "        return {\n",
    "            \"shape\": (new_h, new_w),\n",
    "            \"ref_slide\": ref_slide,\n",
    "            \"ref_types\": ref_types,\n",
    "            \"slide_deck\": slide_deck,\n",
    "            \"lengths_slide_deck\": lengths_slide_deck,\n",
    "            \"length_ref_types\": length_ref_types,\n",
    "        }\n",
    "\n",
    "class LeaveN(object):\n",
    "    def __init__ (self, N):\n",
    "        self.N = N\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        h, w = sample[\"shape\"]\n",
    "        ref_slide = sample['ref_slide']\n",
    "        ref_types = sample[\"ref_types\"]\n",
    "        slide_deck = sample[\"slide_deck\"]\n",
    "        lengths_slide_deck = sample[\"lengths_slide_deck\"]\n",
    "        length_ref_types = sample[\"length_ref_types\"]\n",
    "\n",
    "        if slide_deck.shape[0] > self.N:\n",
    "            slide_deck = np.delete(slide_deck, range(self.N, slide_deck.shape[0]), 0)\n",
    "            lengths_slide_deck = lengths_slide_deck[:self.N]\n",
    "\n",
    "        return {\n",
    "            \"shape\": (h, w),\n",
    "            \"ref_slide\": ref_slide,\n",
    "            \"ref_types\": ref_types,\n",
    "            \"slide_deck\": slide_deck,\n",
    "            \"lengths_slide_deck\": lengths_slide_deck,\n",
    "            \"length_ref_types\": length_ref_types,\n",
    "        }\n",
    "\n",
    "class ShuffleRefSlide(object):\n",
    "    def __call__(self, sample):\n",
    "        h, w = sample[\"shape\"]\n",
    "        ref_slide = sample['ref_slide']\n",
    "        ref_types = sample[\"ref_types\"]\n",
    "        slide_deck = sample[\"slide_deck\"]\n",
    "        lengths_slide_deck = sample[\"lengths_slide_deck\"]\n",
    "        length_ref_types = sample[\"length_ref_types\"]\n",
    "\n",
    "        lengths_slide_deck.append(length_ref_types)\n",
    "        slide_deck = np.vstack((slide_deck, ref_slide[None, :]))\n",
    "\n",
    "        idxs = np.array([*range(0, len(lengths_slide_deck))], dtype=np.int32)\n",
    "        np.random.shuffle(idxs)\n",
    "\n",
    "        slide_deck = slide_deck[idxs]\n",
    "\n",
    "        lengths_slide_deck = np.array(lengths_slide_deck)\n",
    "        lengths_slide_deck = lengths_slide_deck[idxs]\n",
    "        lengths_slide_deck = lengths_slide_deck.tolist()\n",
    "        \n",
    "        slide_deck = slide_deck.tolist()\n",
    "        ref_slide = np.asarray(slide_deck.pop())\n",
    "        length_ref_types = lengths_slide_deck.pop()\n",
    "        ref_types = get_BB_types(ref_slide)\n",
    "\n",
    "        slide_deck = np.asarray(slide_deck)\n",
    "        \n",
    "        return {\n",
    "            \"shape\": (h, w),\n",
    "            \"ref_slide\": ref_slide,\n",
    "            \"ref_types\": ref_types,\n",
    "            \"slide_deck\": slide_deck,\n",
    "            \"lengths_slide_deck\": lengths_slide_deck,\n",
    "            \"length_ref_types\": length_ref_types,\n",
    "        }\n",
    "\n",
    "class ToTensorBB(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        h, w = sample[\"shape\"]\n",
    "        ref_slide = sample[\"ref_slide\"]\n",
    "        ref_types = sample[\"ref_types\"]\n",
    "        slide_deck = sample[\"slide_deck\"]\n",
    "        lengths_slide_deck = sample[\"lengths_slide_deck\"]\n",
    "        length_ref_types = sample[\"length_ref_types\"]\n",
    "        return {\n",
    "            \"shape\": torch.tensor([h, w]),\n",
    "            \"ref_slide\": torch.from_numpy(ref_slide),\n",
    "            \"ref_types\": torch.from_numpy(ref_types),\n",
    "            \"slide_deck\": torch.from_numpy(slide_deck),\n",
    "            \"lengths_slide_deck\": torch.tensor(lengths_slide_deck),\n",
    "            \"length_ref_types\": torch.tensor(length_ref_types)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_TYPES = [\n",
    "    'title',\n",
    "    'header',\n",
    "    'text box',\n",
    "    'footer',\n",
    "    'picture',\n",
    "    'instructor',\n",
    "    'diagram',\n",
    "    'table',\n",
    "    'figure',\n",
    "    'handwriting',\n",
    "    'chart',\n",
    "    'schematic diagram',\n",
    "]\n",
    "\n",
    "def process_slide_deck_dataset(all_dataset):\n",
    "    slide_deck_data = {}\n",
    "    for entrance in all_dataset.iloc:\n",
    "        slide_deck_id = entrance['Slide Deck Id']\n",
    "        \n",
    "        slide_id = entrance[\"Slide Id\"]\n",
    "        if (slide_deck_id not in slide_deck_data):\n",
    "            slide_deck_data[slide_deck_id] = {\n",
    "                'slides': {},\n",
    "                'shape': (entrance['Image Height'], entrance['Image Width'])\n",
    "            }\n",
    "        \n",
    "        if slide_id not in slide_deck_data[slide_deck_id][\"slides\"]:\n",
    "            slide_deck_data[slide_deck_id][\"slides\"][slide_id] = []\n",
    "        bb_type = BB_TYPES.index(entrance['Type'])\n",
    "        if (bb_type < 0 or bb_type >= len(BB_TYPES)):\n",
    "            bb_type = len(BB_TYPES)\n",
    "\n",
    "        bb = np.array([\n",
    "            entrance['X'],\n",
    "            entrance['Y'],\n",
    "            entrance['BB Width'],\n",
    "            entrance['BB Height'],\n",
    "            bb_type + 1\n",
    "        ]).T\n",
    "        slide_deck_data[slide_deck_id]['slides'][slide_id].append(bb)\n",
    "    for key in slide_deck_data.keys():\n",
    "        \n",
    "        # if key == 100:\n",
    "        #     for (id, value) in slide_deck_data[key][\"slides\"].items():\n",
    "        #         print(56, id)\n",
    "        #         draw_bbs(slide_deck_data[key][\"shape\"], value)\n",
    "\n",
    "        values = list(slide_deck_data[key][\"slides\"].values())\n",
    "        slide_deck_data[key][\"slides\"] = [np.asarray(value) for value in values]\n",
    "    return slide_deck_data\n",
    "\n",
    "def slice_dict(dictionary, l, r):\n",
    "    keys = list(dictionary.keys())\n",
    "    keys = keys[l:r]\n",
    "    ret_dictionary = {}\n",
    "    for key in keys:\n",
    "        ret_dictionary[key] = dictionary[key]\n",
    "    return ret_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(os.path.dirname(os.getcwd()), \"data\", \"slide_deck_dataset.csv\")\n",
    "\n",
    "dataset = pd.read_csv(csv_file)\n",
    "slide_deck_data = process_slide_deck_dataset(dataset)\n",
    "\n",
    "division = int(args.train_portion * len(slide_deck_data))\n",
    "\n",
    "train_slide_deck_dataset = BBSlideDeckDataset(\n",
    "    slide_deck_data=slice_dict(slide_deck_data, 0, division),\n",
    "    transform=transforms.Compose([\n",
    "        RescaleBB((1, 1)),\n",
    "        ShuffleRefSlide(),\n",
    "        LeaveN(5),\n",
    "        ToTensorBB()\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_slide_deck_dataset = BBSlideDeckDataset(\n",
    "    slide_deck_data=slice_dict(slide_deck_data, division, len(slide_deck_data)),\n",
    "    transform=transforms.Compose([\n",
    "        RescaleBB((1, 1)),\n",
    "        #ShuffleSlideDeck(),\n",
    "        #ShuffleRefSlide(),\n",
    "        #LeaveN(5),\n",
    "        ToTensorBB()\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sl torch.Size([7, 5])\n",
      "sl torch.Size([7, 5])\n",
      "sl torch.Size([7, 5])\n",
      "sl torch.Size([7, 5])\n",
      "sl torch.Size([7, 5])\n",
      "tensor([3, 7, 4, 5, 4])\n",
      "torch.Size([7, 5]) tensor([5., 1., 3., 0., 0., 0., 0.], dtype=torch.float64) tensor(3)\n"
     ]
    }
   ],
   "source": [
    "single = train_slide_deck_dataset[0]\n",
    "draw_bbs(single[\"shape\"], single[\"ref_slide\"])\n",
    "#print(single)\n",
    "\n",
    "for slide in single[\"slide_deck\"]:\n",
    "    print('sl', slide.size())\n",
    "print(single[\"lengths_slide_deck\"])\n",
    "\n",
    "print(single[\"ref_slide\"].size(), single[\"ref_types\"], single[\"length_ref_types\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_slide_deck_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_slide_deck_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45dc61766396859fdffae760accc4b74216ea8fbbed6d1a9d5e8fb1914e35062"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
